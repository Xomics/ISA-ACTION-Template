{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extra-newman",
   "metadata": {},
   "source": [
    "# Read related files\n",
    "\n",
    "Non-standardized metadata files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "divided-handling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'IDs']"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "input_dir = \"./isa_container/input_files\"\n",
    "os.listdir(path = input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-missouri",
   "metadata": {},
   "source": [
    "## Sample identifiers from ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "valuable-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame dimensions\n",
      " (10, 5)\n",
      "Column names\n",
      " Index(['XOmicsPhenoID', 'XOmicsGenoID', 'XOmicsFamID', 'XOmicsMethylID',\n",
      "       'XOmicsmetaboID'],\n",
      "      dtype='object')\n",
      "Missing value counts\n",
      " XOmicsPhenoID     0\n",
      "XOmicsGenoID      0\n",
      "XOmicsFamID       0\n",
      "XOmicsMethylID    0\n",
      "XOmicsmetaboID    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of   XOmicsPhenoID XOmicsGenoID XOmicsFamID XOmicsMethylID XOmicsmetaboID\n",
       "0          XOP1         XOG1        XOF1           XOE1          XOM1 \n",
       "1          XOP2         XOG2        XOF2           XOE2           XOM2\n",
       "2          XOP3         XOG3        XOF3           XOE3           XOM3\n",
       "3          XOP4         XOG4        XOF4           XOE4           XOM4\n",
       "4          XOP5         XOG5        XOF5           XOE5           XOM5\n",
       "5          XOP6         XOG6        XOF6           XOE6           XOM6\n",
       "6          XOP7         XOG7        XOF7           XOE7           XOM7\n",
       "7          XOP8         XOG8        XOF8           XOE8           XOM8\n",
       "8          XOP9         XOG9        XOF9           XOE9           XOM9\n",
       "9         XOP10        XOG10       XOF10          XOE10          XOM10>"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs_file_path = \"./isa_container/input_files/IDs/ACTIONdemonstrator_XOmics_IDs_fake.csv\"\n",
    "import pandas as pd\n",
    "IDs_df = pd.read_csv(IDs_file_path).iloc[:10,]\n",
    "print(\"Data frame dimensions\\n\", IDs_df.shape)\n",
    "print(\"Column names\\n\", IDs_df.columns)\n",
    "print(\"Missing value counts\\n\", IDs_df.isna().sum())\n",
    "IDs_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a666efa",
   "metadata": {},
   "source": [
    "# Create ISA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "c7603953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/philippe/Documents/git/isa-api2/isa-api/isa-cookbook/content/notebooks'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print current directory\n",
    "import numpy as np\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-maryland",
   "metadata": {},
   "source": [
    "## Investigation\n",
    "\n",
    "Create a new ISA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "composite-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new investigation with single study\n",
    "from isatools.model import *\n",
    "investigation = Investigation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "contemporary-threshold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X-omics data analysis, integration and stewardship demonstrator dataset: NTR ACTION omics data'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define title\n",
    "investigation.title = \"X-omics data analysis, integration and stewardship demonstrator dataset: NTR ACTION omics data\"\n",
    "investigation.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "balanced-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation.description = \"Predict childhood aggression with multi-omics data and demonstrate the FAIRification process and data analysis of a multi-omics project\"\n",
    "investigation.identifier = \"tbd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-student",
   "metadata": {},
   "source": [
    "## Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "sticky-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[isatools.model.Study(filename='', identifier='', title='', description='', submission_date='', public_release_date='', contacts=[], design_descriptors=[], publications=[], factors=[], protocols=[], assays=[], sources=[], samples=[], process_sequence=[], other_material=[], characteristic_categories=[], comments=[], units=[])]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add one study to investigation\n",
    "investigation.studies.append(Study())\n",
    "investigation.studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-opinion",
   "metadata": {},
   "source": [
    "According to MetaboLights help site, the title should ideally be the same as for a corresponding manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "married-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation.studies[0].title = \"X-omics data analysis, integration and stewardship demonstrator dataset: NTR ACTION omics data\"\n",
    "investigation.studies[0].identifier = \"tbd\" # TODO: add identifier; update title\n",
    "investigation.studies[0].filename = \"s_study.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "violent-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isatools.model.Study(filename='s_study.txt', identifier='tbd', title='X-omics data analysis, integration and stewardship demonstrator dataset: NTR ACTION omics data', description='', submission_date='', public_release_date='', contacts=[], design_descriptors=[], publications=[], factors=[], protocols=[], assays=[], sources=[], samples=[], process_sequence=[], other_material=[], characteristic_categories=[], comments=[], units=[])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investigation.studies[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-winter",
   "metadata": {},
   "source": [
    "### Ontologies\n",
    "\n",
    "Ontologies can be searched e.g. at http://www.ontobee.org/ or https://www.ebi.ac.uk/ols/index.\n",
    "\n",
    "FAIR genomes lookups: https://github.com/fairgenomes/fairgenomes-semantic-model/tree/main/lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "considered-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ontologies\n",
    "ontologies = {\n",
    "    \"afo\": OntologySource(\n",
    "        name = \"AFO\",\n",
    "        description = \"Allotrope Merged Ontology Suite\"),\n",
    "    \"chebi\": OntologySource(\n",
    "        name = \"CHEBI\",\n",
    "        description = \"Chemical Entities of Biological Interest\"),\n",
    "    \"chmo\": OntologySource(\n",
    "        name = \"CHMO\", \n",
    "        description = \"Chemical Methods Ontology\"),\n",
    "    \"edam\": OntologySource(\n",
    "        name = \"EDAM\", \n",
    "        description = \"Bioinformatics operations, data types, formats, identifiers and topics\"),\n",
    "    \"efo\": OntologySource(\n",
    "        name = \"EFO\", \n",
    "        description = \"Experimental Factor Ontology\"),\n",
    "    \"ero\": OntologySource(\n",
    "        name = \"eagle-i resource ontology\",\n",
    "        description = \"An ontology of research resources such as instruments, protocols, reagents, animal models and biospecimens\"),\n",
    "    \"maxo\": OntologySource(\n",
    "        name = \"MAXO\", \n",
    "        description = \"Medical Action Ontology\"),\n",
    "    \"msio\": OntologySource(\n",
    "        name = \"MSIO\",\n",
    "        description = \"Metabolite Standards Initiative Ontology\"),\n",
    "    \"ncbitaxon\": OntologySource(\n",
    "        name = \"NCBITAXON\", \n",
    "        description = \"NCBI organismal classification\"),\n",
    "    \"ncit\": OntologySource(\n",
    "        name = \"NCIT\", \n",
    "        description = \"NCI Thesaurus OBO Edition\"),\n",
    "    \"obi\": OntologySource(\n",
    "        name = \"OBI\", \n",
    "        description = \"Ontology for Biomedical Investigations\"),\n",
    "    \"pato\": OntologySource(\n",
    "        name = \"PATO\", \n",
    "        description = \"PATO - the Phenotype And Trait Ontology\"),\n",
    "    \"uberon\": OntologySource(\n",
    "        name = \"UBERON\", \n",
    "        description = \"Uber-anatomy ontology\")\n",
    "}\n",
    "# add ontologies to investigation\n",
    "for o in ontologies.values():\n",
    "    investigation.ontology_source_references.append(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-johns",
   "metadata": {},
   "source": [
    "### Protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-offer",
   "metadata": {},
   "source": [
    "Note that the protocol used in the process to derive `sample` from `source` MUST be of type 'sample collection' (see https://isa-specs.readthedocs.io/en/latest/isatab.html#study-table-file). \n",
    "\n",
    "- ISA model source: https://github.com/ISA-tools/isa-api/blob/master/isatools/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "personal-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_params = {\n",
    "    \"anatomical entity\": ProtocolParameter(\n",
    "            parameter_name = OntologyAnnotation(\n",
    "                term = \"anatomical entity\",\n",
    "                term_source = ontologies[\"uberon\"],\n",
    "                term_accession = \"http://purl.obolibrary.org/obo/UBERON_0001062\"))\n",
    "}\n",
    "# define sample collection protocol\n",
    "sample_collection_protocol = Protocol(\n",
    "    name = \"sample collection\", \n",
    "    # see github.com/ISA-tools/isa-specs/blob/master/source/isatab.rst \n",
    "    # -> MUST be of type 'sample collection'\n",
    "    protocol_type = OntologyAnnotation(term = \"sample collection\"),\n",
    "    parameters = [protocol_params[\"anatomical entity\"]])\n",
    "investigation.studies[0].protocols.append(sample_collection_protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-reducing",
   "metadata": {},
   "source": [
    "### Metabolomics\n",
    "\n",
    "See also https://ebi.ac.uk/metabolights/guides/Protocol/Protocol for protocols required for submission in MetaboLights, i.e. Sample collection, Extraction, Chromatography, Mass spectrometry, Data transformation, and Metabolite identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-movement",
   "metadata": {},
   "source": [
    "### Study factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "spare-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "studyfactor_gender = StudyFactor(\n",
    "    name = \"genotypic sex\", \n",
    "    factor_type = OntologyAnnotation( # Ontology source reference\n",
    "        term = \"genotypic sex\", # also used in FAIR genomes\n",
    "        term_source = ontologies[\"pato\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/PATO_0020000\"))\n",
    "# female\n",
    "factorvalue_female = FactorValue(\n",
    "    factor_name = studyfactor_gender, \n",
    "    value = OntologyAnnotation( # str or OntologyAnnotation\n",
    "        term = \"XX Genotype\", # also used in FAIR genomes\n",
    "        term_source = ontologies[\"ncit\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C45976\"))\n",
    "# male\n",
    "factorvalue_male = FactorValue(\n",
    "    factor_name = studyfactor_gender, \n",
    "    value = OntologyAnnotation( # str or OntologyAnnotation\n",
    "        term = \"XY Genotype\", # also used in FAIR genomes\n",
    "        term_source = ontologies[\"ncit\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C45977\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300e488",
   "metadata": {},
   "source": [
    "## Assays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-arctic",
   "metadata": {},
   "source": [
    "### Genotyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "material-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_genotype = Assay(filename = \"a_assay_genotype.txt\",\n",
    "    measurement_type = OntologyAnnotation(term = \"\", term_source = \"\", term_accession = \"\"),\n",
    "    technology_type = OntologyAnnotation(term = \"nucleotide sequencing\", term_source =\"\", term_accession = \"\"),\n",
    "    technology_platform = OntologyAnnotation(term = \"\", term_source = \"\", term_accession = \"\"))\n",
    "# TODO: What sequencing plaform has been used?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "efficient-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define extraction and measurement protocols\n",
    "dna_extraction_protocol = Protocol(\n",
    "    name = \"DNA extraction\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = \"DNA extraction\",\n",
    "        term_source = ontologies[\"obi\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/OBI_0000257\")) \n",
    "# TODO: check type; compare to FAIR genomes\n",
    "investigation.studies[0].protocols.append(dna_extraction_protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "through-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "genotype_profiling_protocol = Protocol(\n",
    "    name = \"genotype profiling\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = \"genotyping\",\n",
    "        term_source = ontologies[\"efo\"],\n",
    "    term_accession = \"http://www.ebi.ac.uk/efo/EFO_0000750\")\n",
    ")\n",
    "investigation.studies[0].protocols.append(genotype_profiling_protocol)\n",
    "# TODO: check type; compare to FAIR genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-crime",
   "metadata": {},
   "source": [
    "### DNA methylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "ultimate-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_methylation = Assay(\n",
    "    filename = \"a_assay_methylation.txt\", \n",
    "    measurement_type = OntologyAnnotation(\n",
    "        term = \"Methylation Beta Value\",\n",
    "        term_source = ontologies[\"ncit\"],\n",
    "        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C164051\"),\n",
    "    technology_type = OntologyAnnotation(\n",
    "        term = \"DNA methylation profiling by array assay\",\n",
    "        term_source = ontologies[\"obi\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/OBI_0001332\"),\n",
    "    technology_platform = OntologyAnnotation(\n",
    "        term = \"Illumina Infinium MethylationEPIC BeadChip\",\n",
    "        term_source = ontologies[\"obi\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/OBI_0002131\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "sweet-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define extraction and measurement protocols\n",
    "dna_extraction_protocol = Protocol(\n",
    "    name = \"DNA extraction\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = \"DNA extraction\",\n",
    "        term_source = ontologies[\"obi\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/OBI_0000257\")) \n",
    "# TODO: check type; compare to FAIR genomes\n",
    "investigation.studies[0].protocols.append(dna_extraction_protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "cleared-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "methylation_profiling_protocol = Protocol(\n",
    "    name = \"methylation profiling\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = \"methylation profiling\",\n",
    "        term_source = ontologies[\"efo\"], \n",
    "        term_accession = \"http://www.ebi.ac.uk/efo/EFO_0000751\"),\n",
    "#    components = [OntologyAnnotation(\n",
    "#        term = \"Illumina Infinium MethylationEPIC BeadChip\",\n",
    "#        term_source = obi, \n",
    "#        term_accession = \"http://purl.obolibrary.org/obo/OBI_0002131\")]\n",
    "    ) \n",
    "investigation.studies[0].protocols.append(methylation_profiling_protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "answering-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    " methylation_data_processing_protocol = Protocol(\n",
    "    name = \"methylation data processing protocol\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = \"Protocol\",\n",
    "        term_source = ontologies[\"edam\"], \n",
    "        term_accession = \"http://edamontology.org/data_2531\"),\n",
    "    description = \"Sinke, Lucy, van Iterson, Maarten, Cats, Davy, Slieker, Roderick, & Heijmans, Bas. (2019, July 11). DNAmArray: Streamlined workflow for the quality control, normalization, and analysis of Illumina methylation array data (Version 2.1). Zenodo. http://doi.org/10.5281/zenodo.3355292\",\n",
    "    uri = \"http://doi.org/10.5281/zenodo.3355292\")\n",
    "investigation.studies[0].protocols.append(methylation_data_processing_protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-iraqi",
   "metadata": {},
   "source": [
    "### Metabolomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "digital-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_metabolomics_amines = Assay(\n",
    "    filename = \"a_assay_metabolomics_amines.txt\",\n",
    "\n",
    "    \n",
    "    measurement_type = OntologyAnnotation(\n",
    "        term = \"targeted metabolite profiling\",\n",
    "        term_source = ontologies[\"msio\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/MSIO_0000100\"),\n",
    "    \n",
    "    technology_type = OntologyAnnotation(\n",
    "        term = \"liquid chromatography-mass spectrometry\",\n",
    "        term_source = ontologies[\"chmo\"],\n",
    "        term_accession = \"http://purl.obolibrary.org/obo/CHMO_0000524\"))\n",
    "    \n",
    "#     sample_type = OntologyAnnotation(\n",
    "#         term = \"urine specimen\",\n",
    "#         term_source = ['obi'],\n",
    "#         term_accession = \"http:/purl.obolibrary.org/obo/OBI_0000651\")\n",
    "    \n",
    "\n",
    "#     \n",
    "#     technology_platform = OntologyAnnotation(\n",
    "#         term = \"\",\n",
    "#         term_source = ontologies[\"\"], \n",
    "#         term_accession = \"\")\n",
    "    # TODO: What exact platform/instrument has been used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "enormous-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_metabolomics_OA = Assay(\n",
    "    filename = \"a_assay_metabolomics_OA.txt\", \n",
    "    \n",
    "    measurement_type = OntologyAnnotation(\n",
    "        term = \"targeted metabolite profiling\",\n",
    "        term_source = ontologies[\"msio\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/MSIO_0000100\"),\n",
    "    \n",
    "    technology_type = OntologyAnnotation(\n",
    "        term = \"gas chromatography-mass spectrometry\",\n",
    "        term_source = ontologies[\"chmo\"]))\n",
    "        \n",
    "#     sample_type = OntologyAnnotation(\n",
    "#         term = \"urine specimen\",\n",
    "#         term_source = ['obi'],\n",
    "#         term_accession = \"http:/purl.obolibrary.org/obo/OBI_0000651\")\n",
    "    \n",
    "    \n",
    "#     technology_platform = OntologyAnnotation(\n",
    "#         term = \"\",\n",
    "#         term_source = ontologies[\"\"], \n",
    "#         term_accession = \"\")\n",
    "        # TODO: What exact platform/instrument has been used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "equipped-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_metabolomics_steroids = Assay(\n",
    "    filename = \"a_assay_metabolomics_steroids.txt\", \n",
    "    \n",
    "    measurement_type = OntologyAnnotation(\n",
    "        term = \"targeted metabolite profiling\",\n",
    "        term_source = ontologies[\"msio\"], \n",
    "        term_accession = \"http://purl.obolibrary.org/obo/MSIO_0000100\"),\n",
    "    \n",
    "    technology_type = OntologyAnnotation(\n",
    "        term = \"high-performance liquid chromatography-mass spectrometry\",\n",
    "        term_source = ontologies[\"chmo\"],\n",
    "        term_accession = \"http://purl.obolibrary.org/obo/CHMO_0000796\"))\n",
    "    \n",
    "#     sample_type = OntologyAnnotation(\n",
    "#         term = \"urine specimen\",\n",
    "#         term_source = ['obi'],\n",
    "#         term_accession = \"http:/purl.obolibrary.org/obo/OBI_0000651\")\n",
    "\n",
    "#     technology_platform = OntologyAnnotation(\n",
    "#         term = \"\",\n",
    "#         term_source = ontologies[\"\"], \n",
    "#         term_accession = \"\")\n",
    "# TODO: What exact platform/instrument has been used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "systematic-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_sampling_protocol = Protocol(\n",
    "    name = \"urine sampling\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'urine speciment collection',\n",
    "#         term_source = [''],\n",
    "        term_accession = 'http://snomed.info/id/57617002')\n",
    ")\n",
    "# TODO: is this useful a ontology?\n",
    "\n",
    "\n",
    "investigation.studies[0].protocols.append(urine_sampling_protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "greatest-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_metabolomics = Protocol(\n",
    "    name = \"Extraction\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'Extraction',\n",
    "        term_source = ontologies[\"ncit\"],\n",
    "        term_accession = 'http://purl.obolibrary.org/obo/NCIT_C61575'),\n",
    "    parameters = [\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Post Extraction\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Derivatization\"))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "center-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromatography = Protocol(\n",
    "    name = \"Chromatography\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'Chromatography',\n",
    "        term_source = ontologies[\"ncit\"],\n",
    "        term_accession = 'http://purl.obolibrary.org/obo/NCIT_C16431'),\n",
    "    parameters = [\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Chromatography Instrument\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Column model\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Column type\"))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "boolean-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling_metabolites = Protocol(\n",
    "    name = \"Labelling metabolites\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'Labelling',\n",
    "        term_source = ontologies[\"chmo\"],\n",
    "        term_accession = 'http://purl.obolibrary.org/obo/CHMO_0001675')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "responsible-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_spectrometry = Protocol(\n",
    "    name = \"Mass spectrometry\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'Mass spectrometry',\n",
    "        term_source = ontologies[\"ncit\"],\n",
    "        term_accession = 'http://purl.obolibrary.org/obo/NCIT_C17156'),\n",
    "    parameters = [\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Scan polarity\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Scan m/z range\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Instrument\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Ion source\")),\n",
    "        ProtocolParameter(parameter_name=OntologyAnnotation(term = \"Mass analyzer\"))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "incorporated-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation = Protocol(\n",
    "    name = \"Data transformation\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'Data Transformation',\n",
    "        term_source = ontologies[\"ncit\"],\n",
    "        term_accession = 'http://purl.obolibrary.org/obo/NCIT_C43582')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "minimal-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolite_identification = Protocol(\n",
    "    name = \"Metabolite identification\",\n",
    "    protocol_type = OntologyAnnotation(\n",
    "        term = 'peak identification',\n",
    "        term_source = ontologies[\"afo\"],\n",
    "        term_accession = 'http://purl.allotrope.erg/ontologies/process#AFP_0003618')\n",
    "    )\n",
    "\n",
    "# TODO: Is this the correct ontlogy (source)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-technique",
   "metadata": {},
   "source": [
    "## ACTION samples\n",
    "\n",
    "Add samples to study and link to previously defined protocols and assays.\n",
    "\n",
    "For MetaboLights, sample information should include unique sample name, organism, organism part, sample type (control, QC, experimental sample), other descriptors as factors (age, gender)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "floating-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in IDs_df.iterrows(): \n",
    "    # add subjects (sources) \n",
    "    # TODO: issue - source should represent a source material such as urine, \n",
    "    #   and sample a respective extract or similar\n",
    "    # check if source was already added already (rows can contain duplicate entries)\n",
    "    #is_new_source = True\n",
    "    source_name = row[\"XOmicsPhenoID\"]\n",
    "    source = next((src for src in investigation.studies[0].sources \n",
    "                   if src.name == source_name), None)\n",
    "    if not source:\n",
    "        #is_new_source = False\n",
    "        # create new source for subject\n",
    "        source = Source(name = row[\"XOmicsPhenoID\"])\n",
    "        # Characteristics - Organism - should be included for Metabolights\n",
    "        # here, organism is defined per source, i.e. individual\n",
    "        source.characteristics.append(\n",
    "            Characteristic(\n",
    "                category = OntologyAnnotation(\n",
    "                    term = \"organism\"), \n",
    "                # TODO: add term source and accession for category? would such information be lost in ISA-Tab?\n",
    "                value = OntologyAnnotation(\n",
    "                    term = \"Homo sapiens\",\n",
    "                    term_source = ontologies[\"ncbitaxon\"],\n",
    "                    term_accession = \"http://purl.bioontology.org/ontology/NCBITAXON/9606\")))\n",
    "        # TODO: check if family ID should/should not be added / is required for analysis\n",
    "        source.characteristics.append(\n",
    "            Characteristic(category = \"family ID\",\n",
    "                           value = row[\"XOmicsFamID\"]))\n",
    "        source.characteristics.append(\n",
    "            Characteristic(\n",
    "                category = OntologyAnnotation( \n",
    "                    term = \"childhood aggressive behaviour measurement\", \n",
    "                    term_source = ontologies[\"efo\"], \n",
    "                    term_accession = \"http://www.ebi.ac.uk/efo/EFO_0007663\"),\n",
    "                value = \"\", #tscore,\n",
    "                unit = OntologyAnnotation( \n",
    "                    term = \"T-score\", \n",
    "                    term_source = ontologies[\"ncit\"], \n",
    "                    term_accession = \"http://purl.obolibrary.org/obo/NCIT_C120401\")))\n",
    "        #source.factor_values.append(FactorValueAggressionScore(value = tscore))\n",
    "        \n",
    "        # add subject to study\n",
    "        investigation.studies[0].sources.append(source)\n",
    "        \n",
    "    # add samples - sample names need to be unique\n",
    "    # urine sample for metabolomics\n",
    "    if not pd.isna(row[\"XOmicsmetaboID\"]):\n",
    "        # check if urine sample was already added to study\n",
    "        urine_sample_name = \"urine_{0}\".format(source_name)\n",
    "        urine_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "        if not urine_sample:\n",
    "            # create a new sample with unique name\n",
    "            urine_sample = Sample(\n",
    "                name = urine_sample_name, \n",
    "                derives_from = [source]) # the individual\n",
    "            # Characteristics - Organism part - should be included for Metabolights\n",
    "            # here, organism part is defined per sample\n",
    "            urine_sample.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(term = \"organism part\"),\n",
    "                    value = OntologyAnnotation(\n",
    "                        term = \"urine\",\n",
    "                        term_source = ontologies[\"uberon\"],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/UBERON_0001088\")))\n",
    "            # Characteristics - sample type - should be included for Metabolights \n",
    "            # i.e. control, QC, experimental sample\n",
    "            urine_sample.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = \"sample type\", # TODO: could not find a term yet; sample type is not an ontological term, but required by MetaboLights\n",
    "                    value = OntologyAnnotation(\n",
    "                        term = \"experimental sample\",\n",
    "                        term_source = ontologies[\"chmo\"],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/CHMO_0002746\")))\n",
    "            # add urine sample to study\n",
    "            investigation.studies[0].samples.append(urine_sample)\n",
    "            \n",
    "            # check if urine sampling process exists for source\n",
    "            urine_p_name = \"urine_specimen_collection_process_{0}\".format(source.name)\n",
    "            urine_collection_process = next(\n",
    "                (prcs for prcs in investigation.studies[0].process_sequence \n",
    "                 if prcs.name == urine_p_name), None)\n",
    "            if not urine_collection_process:\n",
    "                # define urine sampling process for this subject\n",
    "                urine_collection_process = Process(\n",
    "                    name = urine_p_name, \n",
    "                    executes_protocol = sample_collection_protocol,\n",
    "                    parameter_values = [\n",
    "                        ParameterValue(\n",
    "                            category = protocol_params[\"anatomical entity\"], #ProtocolParameter \n",
    "                            value = \"urine\")],\n",
    "                    inputs = [source],\n",
    "                    outputs = [urine_sample])\n",
    "                investigation.studies[0].process_sequence.append(urine_collection_process)\n",
    "            else:\n",
    "                # urine sampling process already exists for the source\n",
    "                # add urine sample to outputs of existing process\n",
    "                urine_collection_process.outputs.append(urine_sample)\n",
    "    \n",
    "    # add samples\n",
    "    # buccal swab sample for genotyping and DNA methylation arrays\n",
    "    if not pd.isna(row[\"XOmicsGenoID\"]) or not pd.isna(row[\"XOmicsMethylID\"]):\n",
    "        buccal_sample_name = \"buccal_mucosa_{0}\".format(source_name)\n",
    "        \n",
    "        buccal_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == buccal_sample_name), None)\n",
    "        \n",
    "        if not buccal_sample:\n",
    "            # create sample of buccal mucosa\n",
    "            buccal_sample = Sample(\n",
    "                name = buccal_sample_name, \n",
    "                derives_from = [source]) # same source as urine sample\n",
    "            buccal_sample.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(term = \"organism part\"),\n",
    "                    value = \"\"))\n",
    "            # TODO: add more characteristics - compare to urime sample\n",
    "            # add sample to study\n",
    "            investigation.studies[0].samples.append(buccal_sample) \n",
    "            \n",
    "            # check if buccal swab sampling process exists for source\n",
    "            # needs to be checked, because multiple samples can be derived from one source\n",
    "            buccal_p_name = \"buccal_specimen_collection_process_{0}\".format(source.name)\n",
    "            buccal_collection_process = next(\n",
    "                (prcs for prcs in investigation.studies[0].process_sequence \n",
    "                 if prcs.name == buccal_p_name), None)\n",
    "            if not buccal_collection_process:\n",
    "                # define buccal sampling process for this subject\n",
    "                buccal_collection_process = Process(\n",
    "                    name = buccal_p_name, \n",
    "                    executes_protocol = sample_collection_protocol,\n",
    "                    parameter_values = [\n",
    "                        ParameterValue(\n",
    "                            category = protocol_params[\"anatomical entity\"], #ProtocolParameter \n",
    "                            value = \"buccal mucosa\")],\n",
    "                    inputs = [source],\n",
    "                    outputs = [buccal_sample]\n",
    "                )\n",
    "                investigation.studies[0].process_sequence.append(buccal_collection_process)\n",
    " \n",
    "            else:\n",
    "                # buccal sampling process already exists for the source\n",
    "                # add buccal sample to outputs of existing process\n",
    "                buccal_collection_process.outputs.append(buccal_sample)\n",
    "                \n",
    "            # NOTE: adding extraction process at study level doesn seem to work\n",
    "            # causes sample to disappear from study file\n",
    "            \n",
    "                \n",
    "\n",
    "        #if not pd.isna(row[\"XOmicsMethylID\"]):\n",
    "        #    dna_extraction_process = next(())\n",
    "        #    assay_methylation.samples.append(buccal_sample) # first check if already added\n",
    "        #    methylation_profiling_process = Process(\n",
    "        #            name = \"methylation_profiling_{0}\".format(source.name),\n",
    "        #            executes_protocol = methylation_profiling_protocol,\n",
    "        #            inputs = [buccal_sample], \n",
    "        ##            outputs = [buccal_dna])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-budapest",
   "metadata": {},
   "source": [
    "Genotype assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "honey-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add samples to genotype assay\n",
    "for idx, row in IDs_df.iterrows(): \n",
    "    source_name = row[\"XOmicsPhenoID\"]\n",
    "    if not pd.isna(row[\"XOmicsGenoID\"]):\n",
    "        buccal_sample_name = \"buccal_mucosa_{0}\".format(source_name)\n",
    "        buccal_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == buccal_sample_name), None)\n",
    "        genotype_sample = next(\n",
    "            (smpl for smpl in assay_genotype.samples \n",
    "             if smpl.name == buccal_sample_name), None)\n",
    "        if not genotype_sample:\n",
    "            assay_genotype.samples.append(buccal_sample) # first check if already added\n",
    "            # define DNA as material extracted from buccal mucosa sample\n",
    "            # on study level, because the same DNA is used for genotyping AND DNA methylation profiling\n",
    "            # TODO: check if this works; could be that extraction has to be on assay level\n",
    "            # but Study object has process_sequence, i.e. this is technically possible \n",
    "            # define DNA material for this sample\n",
    "            # now trying on assay level\n",
    "            buccal_dna = Material(\n",
    "                name = \"buccal_DNA_{0}\".format(row[\"XOmicsGenoID\"]),\n",
    "                type_ = \"Extract Name\")\n",
    "            # define extraction process for buccal DNA\n",
    "            dna_extraction_process = Process(\n",
    "                name = \"DNA_extraction_{0}\".format(row[\"XOmicsGenoID\"]),\n",
    "                executes_protocol = dna_extraction_protocol,\n",
    "                inputs = [buccal_sample], \n",
    "                outputs = [buccal_dna])\n",
    "            \n",
    "\n",
    "            #if not pd.isna(row[\"XOmicsMethylID\"]):\n",
    "            #    dna_extraction_process = next(())\n",
    "\n",
    "            genotype_profiling_process = Process(\n",
    "                name = \"genotype_profiling_{0}\".format(row[\"XOmicsGenoID\"]),\n",
    "                executes_protocol = genotype_profiling_protocol,\n",
    "                inputs = [buccal_dna])\n",
    "            \n",
    "            plink(dna_extraction_process, genotype_profiling_process)\n",
    "            assay_genotype.process_sequence.append(dna_extraction_process) \n",
    "            assay_genotype.process_sequence.append(genotype_profiling_process) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "vietnamese-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add samples to methylation assay\n",
    "for idx, row in IDs_df.iterrows(): \n",
    "    source_name = row[\"XOmicsPhenoID\"]\n",
    "    if not pd.isna(row[\"XOmicsMethylID\"]):\n",
    "        buccal_sample_name = \"buccal_mucosa_{0}\".format(source_name)\n",
    "        buccal_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == buccal_sample_name), None)\n",
    "        methylation_sample = next(\n",
    "            (smpl for smpl in assay_methylation.samples \n",
    "             if smpl.name == buccal_sample_name), None)\n",
    "        if not methylation_sample:\n",
    "            assay_methylation.samples.append(buccal_sample) # first check if already added\n",
    "            # define DNA as material extracted from buccal mucosa sample\n",
    "            # on study level, because the same DNA is used for genotyping AND DNA methylation profiling\n",
    "            # TODO: check if this works; could be that extraction has to be on assay level\n",
    "            # but Study object has process_sequence, i.e. this is technically possible \n",
    "            # define DNA material for this sample\n",
    "            # now trying on assay level\n",
    "            buccal_dna = Material(\n",
    "                name = \"buccal_DNA_{0}\".format(row[\"XOmicsMethylID\"]),\n",
    "                type_ = \"Extract Name\")\n",
    "            # define extraction process for buccal DNA\n",
    "            dna_extraction_process = Process(\n",
    "                name = \"DNA_extraction_{0}\".format(row[\"XOmicsMethylID\"]),\n",
    "                executes_protocol = dna_extraction_protocol,\n",
    "                inputs = [buccal_sample], \n",
    "                outputs = [buccal_dna])\n",
    "            \n",
    "\n",
    "            #if not pd.isna(row[\"XOmicsMethylID\"]):\n",
    "            #    dna_extraction_process = next(())\n",
    "\n",
    "            methylation_profiling_process = Process(\n",
    "                name = \"methylation_profiling_{0}\".format(row[\"XOmicsMethylID\"]),\n",
    "                executes_protocol = methylation_profiling_protocol,\n",
    "                inputs = [buccal_dna])\n",
    "            \n",
    "            plink(dna_extraction_process, methylation_profiling_process)\n",
    "            assay_methylation.process_sequence.append(dna_extraction_process) \n",
    "            assay_methylation.process_sequence.append(methylation_profiling_process) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-trinidad",
   "metadata": {},
   "source": [
    "Metabolomics assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "residential-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add samples, processes and datafiles to metabolomics Amines assay\n",
    "\n",
    "Assay = assay_metabolomics_amines\n",
    "\n",
    "# Define datafiles (not all may be relevant)\n",
    "\n",
    "raw_datafile = DataFile(filename=\"link/to/raw/data\", label=\"Raw Spectral Data File\")\n",
    "\n",
    "normalized_datafile = DataFile(filename=\"link/to/normalized_data\", label=\"Normalization Name\")\n",
    "\n",
    "derived_spectral_data_file = DataFile(filename=\"link/to/spectral_file\", label=\"Derived Spectral Data File\")\n",
    "\n",
    "Data_Transformation_Name = DataFile(filename=\"link/to/data_transformation_name\", label=\"Data Transformation Name\")\n",
    "\n",
    "MAF = DataFile(filename=\"link/to/MAF\", label=\"Metabolite Assignment File\")\n",
    "  \n",
    "\n",
    "# Loop over samples and add process to samples\n",
    "for idx, row in IDs_df.iterrows():\n",
    "    source_name = row[\"XOmicsPhenoID\"]\n",
    "#     print(source_name)\n",
    "    if not pd.isna(row[\"XOmicsmetaboID\"]):    \n",
    "        #         print(row['XOmicsmetaboID'])\n",
    "        urine_sample_name = \"urine_{0}\".format(source_name)\n",
    "#         print(urine_sample_name)\n",
    "        urine_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "\n",
    "        metabolomics_sample = next(\n",
    "            (smpl for smpl in Assay.samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "        \n",
    "        if not metabolomics_sample:\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## Extraction\n",
    "            Post_extraction = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Post Extraction\")), value = OntologyAnnotation(term=\"1 uL borate buffer (pH 8.8) with AQC reagent\"))\n",
    "            Derivatization = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Derivatization\")), value = \"AQC\")\n",
    "            \n",
    "            material_extract = Material(\n",
    "                name = \"extract_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                type_ = \"Extract Name\")\n",
    "            \n",
    "            extraction_process = Process(\n",
    "                executes_protocol=extraction_metabolomics, \n",
    "                parameter_values=[Post_extraction, Derivatization],\n",
    "                inputs = [urine_sample],\n",
    "                outputs = [material_extract])\n",
    "            \n",
    "            \n",
    "            ## Labeling\n",
    "            material_label = Material(\n",
    "                name =\"labeled_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                type_ =\"Labeled Extract Name\")\n",
    "            \n",
    "            labelling_process = Process(\n",
    "                executes_protocol=labelling_metabolites,\n",
    "                inputs = [extraction_process.outputs[0]],\n",
    "                outputs = [material_label])\n",
    "            \n",
    "            \n",
    "            ## Chromatography\n",
    "#             separated_molecules = Material(\n",
    "#                 name = \"separated_molecules_{0}\".format(row[\"XOmicsmetaboID\"],\n",
    "#                 type_ =\"Labeled Extract Name\")\n",
    "#             )\n",
    "            \n",
    "            instrument = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Chromatography Instrument\")), value = \"Agilent 1290 Infinity II\")\n",
    "            column_model = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Column model\")), value = \"Accq-Tag Ultra column (waters + FURHTER SPECS?)\")\n",
    "            column_type = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Column type\")), value = \"reverse phase\")\n",
    "\n",
    "            chromatography_process = Process(\n",
    "                name = \"chromatography_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol = chromatography,\n",
    "                parameter_values = [instrument, column_model, column_type],\n",
    "                inputs = [labelling_process.outputs[0]],\n",
    "                outputs = []\n",
    "#                 outputs = [separated_molecules]\n",
    "            )\n",
    "            \n",
    "            \n",
    "            ## Mass spectrometry\n",
    "            scan_polarity = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Scan polarity\")), value = \"positive\")\n",
    "            scan_range = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Scan m/z range\")), value = \"5-2000?\")\n",
    "            instrument = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Instrument\")), value = \"AB SCIEX Qtrap 6500\")\n",
    "            ion_source = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Ion source\")), value = \"ESI\")\n",
    "            mass_analyzer = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Mass Analyzer\")), value = \"triple quadrupole linear ion trap\")\n",
    "            \n",
    "            mass_spectrometry_process = Process(\n",
    "                name = \"mass_spectrometry_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol= mass_spectrometry,\n",
    "                parameter_values = [scan_polarity, scan_range, instrument, ion_source, mass_analyzer],\n",
    "#                 inputs = [separated_molecules],\n",
    "                inputs = [],\n",
    "                outputs = [raw_datafile]\n",
    "            )\n",
    "            \n",
    "            \n",
    "           ## Data transformation\n",
    "            data_transformation_process = Process(\n",
    "                name = \"data_transformation_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol = data_transformation,\n",
    "                inputs = [raw_datafile],\n",
    "                outputs  = [normalized_datafile, derived_spectral_data_file]\n",
    "            )\n",
    "            \n",
    "            \n",
    "            ## Metabolite identification\n",
    "            metabolite_identification_process = Process(\n",
    "                name = \"metabolite_identification_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol =  metabolite_identification,\n",
    "                inputs = [normalized_datafile],\n",
    "                outputs= [Data_Transformation_Name, MAF]\n",
    "            )\n",
    "            \n",
    "            \n",
    "            # Link processes\n",
    "            plink(extraction_process, labelling_process)\n",
    "            plink(labelling_process, chromatography_process)\n",
    "            plink(chromatography_process, mass_spectrometry_process)\n",
    "            plink(mass_spectrometry_process, data_transformation_process)\n",
    "            plink(data_transformation_process, metabolite_identification_process)\n",
    "            \n",
    "            \n",
    "            # Add samples, materials and data files to the amines assay\n",
    "            Assay.samples.append(urine_sample)\n",
    "            Assay.other_material.append(material_extract)\n",
    "            Assay.other_material.append(material_label)\n",
    "#             Assay.other_material.append(separated_molecules)\n",
    "            Assay.data_files.append(raw_datafile)\n",
    "            Assay.data_files.append(normalized_datafile)\n",
    "            Assay.data_files.append(derived_spectral_data_file)\n",
    "            Assay.data_files.append(Data_Transformation_Name)                                                                                                   \n",
    "            Assay.data_files.append(MAF)\n",
    "            \n",
    "            \n",
    "            ## Add processes to the amines assay\n",
    "            Assay.process_sequence.append(extraction_process)\n",
    "            Assay.process_sequence.append(labelling_process)\n",
    "            Assay.process_sequence.append(chromatography_process)\n",
    "            Assay.process_sequence.append(mass_spectrometry_process)\n",
    "            Assay.process_sequence.append(data_transformation_process)\n",
    "            Assay.process_sequence.append(metabolite_identification_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "informal-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add samples, processes and datafiles to metabolomics OA assay\n",
    "\n",
    "Assay = assay_metabolomics_OA\n",
    "\n",
    "# Define datafiles (not all may be relevant)\n",
    "\n",
    "raw_datafile = DataFile(filename=\"link/to/raw/data\", label=\"Raw Spectral Data File\")\n",
    "\n",
    "normalized_datafile = DataFile(filename=\"link/to/normalized_data\", label=\"Normalization Name\")\n",
    "\n",
    "derived_spectral_data_file = DataFile(filename=\"link/to/spectral_file\", label=\"Derived Spectral Data File\")\n",
    "\n",
    "Data_Transformation_Name = DataFile(filename=\"link/to/data_transformation_name\", label=\"Data Transformation Name\")\n",
    "\n",
    "MAF = DataFile(filename=\"link/to/MAF\", label=\"Metabolite Assignment File\")\n",
    "  \n",
    "\n",
    "# Loop over samples and add process to samples\n",
    "for idx, row in IDs_df.iterrows():\n",
    "    source_name = row[\"XOmicsPhenoID\"]\n",
    "#     print(source_name)\n",
    "    if not pd.isna(row[\"XOmicsmetaboID\"]):\n",
    "#         print(row['XOmicsmetaboID'])\n",
    "        urine_sample_name = \"urine_{0}\".format(source_name)\n",
    "#         print(urine_sample_name)\n",
    "        urine_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "\n",
    "        metabolomics_sample = next(\n",
    "            (smpl for smpl in Assay.samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "        \n",
    "        if not metabolomics_sample:\n",
    "            Assay.samples.append(urine_sample)\n",
    "            \n",
    "            \n",
    "            ## Extraction\n",
    "            Post_extraction = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Post Extraction\")), value = \"1 uL pyridine\")\n",
    "            Derivatization = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Derivatization\")), value = \"oximation followed by silylation\")\n",
    "            \n",
    "       \n",
    "            \n",
    "            material_extract = Material(\n",
    "                name = \"extract_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                type_ = \"Extract Name\")\n",
    "                \n",
    "            extraction_process = Process(\n",
    "                executes_protocol=extraction_metabolomics, \n",
    "                parameter_values=[Post_extraction, Derivatization],\n",
    "                inputs = [urine_sample],\n",
    "                outputs = [material_extract])\n",
    "            \n",
    "            \n",
    "            ## Labeling\n",
    "            material_label = Material(\n",
    "                name =\"labeled_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                type_ =\"Labeled Extract Name\")\n",
    "\n",
    "            \n",
    "            labelling_process = Process(\n",
    "                executes_protocol=labelling_metabolites,\n",
    "                inputs = [extraction_process.outputs[0]],\n",
    "                outputs = [material_label])\n",
    "            \n",
    "            \n",
    "#             ## Chromatography\n",
    "#             separated_molecules = Material(\n",
    "#                 name = \"separated_molecules_{0}\".format(row[\"XOmicsmetaboID\"],\n",
    "#                 type_ =\"Labeled Extract Name\")\n",
    "#             )\n",
    "            \n",
    "            instrument = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Chromatography Instrument\")), value = \"Agilent Technologies 7890A\")\n",
    "            column_model = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Column model\")), value = \"HP-5MS UI (5% Phenyl Methyl Silox), 30 m x 0.25 m ID column with a film thickness of 25 um\")\n",
    "            column_type = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Column type\")), value = \"low polarity\")\n",
    "\n",
    "            \n",
    "            chromatography_process = Process(\n",
    "                name = \"chromatography_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol = chromatography,\n",
    "                parameter_values = [instrument, column_model, column_type],\n",
    "                inputs = [labelling_process.outputs[0]], \n",
    "                outputs = [],\n",
    "#                 outputs = [separated_molecules]\n",
    "            )\n",
    "            \n",
    "            ## Mass spectrometry\n",
    "            scan_polarity = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Scan polarity\")), value = \"positive\")\n",
    "            scan_range = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Scan m/z range\")), value = \"50-500\")\n",
    "            instrument = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Instrument\")), value = \"Agilent Technologies mass selective detector (MSD 5975C) and MultiPurpose Sampler (MPS, MXY016-02A, GERSTEL)\")\n",
    "            ion_source = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Ion source\")), value = \"EI (70 eV)\")\n",
    "            mass_analyzer = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Mass Analyzer\")), value = \"single-quadrupole\")\n",
    "            \n",
    "            \n",
    "            mass_spectrometry_process = Process(\n",
    "                name = \"mass_spectrometry_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol= mass_spectrometry,\n",
    "                parameter_values = [scan_polarity, scan_range, instrument, ion_source, mass_analyzer],\n",
    "                inputs = [],\n",
    "#                 inputs = [separated_molecules],\n",
    "                outputs = [raw_datafile]\n",
    "            )\n",
    "            \n",
    "            \n",
    "           ## Data transformation\n",
    "            data_transformation_process = Process(\n",
    "                name = \"data_transformation_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol = data_transformation,\n",
    "                inputs = [raw_datafile],\n",
    "                outputs  = [normalized_datafile, derived_spectral_data_file]\n",
    "            )\n",
    "            \n",
    "            ## Metabolite identification\n",
    "            metabolite_identification_process = Process(\n",
    "                name = \"metabolite_identification_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol =  metabolite_identification,\n",
    "                inputs = [normalized_datafile],\n",
    "                outputs= [Data_Transformation_Name, MAF]\n",
    "            )\n",
    "            \n",
    "            ## Link processes\n",
    "            plink(extraction_process, labelling_process)\n",
    "            plink(labelling_process, chromatography_process)\n",
    "            plink(chromatography_process, mass_spectrometry_process)\n",
    "            plink(mass_spectrometry_process, data_transformation_process)\n",
    "            plink(data_transformation_process, metabolite_identification_process)\n",
    "            \n",
    "            ## Add samples, materials and data files to the OA assay\n",
    "            Assay.other_material.append(material_extract)\n",
    "            Assay.other_material.append(material_label)\n",
    "#             Assay.other_material.append(separated_molecules)\n",
    "            Assay.data_files.append(raw_datafile)\n",
    "            Assay.data_files.append(normalized_datafile)\n",
    "            Assay.data_files.append(derived_spectral_data_file)\n",
    "            Assay.data_files.append(Data_Transformation_Name)                                                                                                   \n",
    "            Assay.data_files.append(MAF)\n",
    "            \n",
    "            ## Add processes to the OA assay\n",
    "            Assay.process_sequence.append(extraction_process)\n",
    "            Assay.process_sequence.append(labelling_process)\n",
    "            Assay.process_sequence.append(chromatography_process)\n",
    "            Assay.process_sequence.append(mass_spectrometry_process)\n",
    "            Assay.process_sequence.append(data_transformation_process)\n",
    "            Assay.process_sequence.append(metabolite_identification_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "silent-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add samples, processes and datafiles to metabolomics steroids assay\n",
    "\n",
    "Assay = assay_metabolomics_steroids\n",
    "\n",
    "# Define datafiles (not all may be relevant)\n",
    "\n",
    "raw_datafile = DataFile(filename=\"link/to/raw/data\", label=\"Raw Spectral Data File\")\n",
    "\n",
    "normalized_datafile = DataFile(filename=\"link/to/normalized_data\", label=\"Normalization Name\")\n",
    "\n",
    "derived_spectral_data_file = DataFile(filename=\"link/to/spectral_file\", label=\"Derived Spectral Data File\")\n",
    "\n",
    "Data_Transformation_Name = DataFile(filename=\"link/to/data_transformation_name\", label=\"Data Transformation Name\")\n",
    "\n",
    "MAF = DataFile(filename=\"link/to/MAF\", label=\"Metabolite Assignment File\")\n",
    "  \n",
    "\n",
    "# Loop over samples and add process to samples\n",
    "for idx, row in IDs_df.iterrows():\n",
    "    source_name = row[\"XOmicsPhenoID\"]\n",
    "#     print(source_name)\n",
    "    if not pd.isna(row[\"XOmicsmetaboID\"]):\n",
    "#         print(row['XOmicsmetaboID'])\n",
    "        urine_sample_name = \"urine_{0}\".format(source_name)\n",
    "#         print(urine_sample_name)\n",
    "        urine_sample = next(\n",
    "            (smpl for smpl in investigation.studies[0].samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "\n",
    "        metabolomics_sample = next(\n",
    "            (smpl for smpl in Assay.samples \n",
    "             if smpl.name == urine_sample_name), None)\n",
    "        \n",
    "        if not metabolomics_sample:\n",
    "            Assay.samples.append(urine_sample)\n",
    "            \n",
    "            \n",
    "            ## Extraction\n",
    "            Post_extraction = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Post Extraction\")), value = \"1 uL filtered urine\")\n",
    "            Derivatization = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Derivatization\")), value = \"NA\")\n",
    "\n",
    "            \n",
    "            material_extract = Material(\n",
    "                name = \"extract_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                type_ = \"Extract Name\")\n",
    "            \n",
    "            extraction_process = Process(\n",
    "                executes_protocol=extraction_metabolomics, \n",
    "                parameter_values=[Post_extraction, Derivatization],\n",
    "                inputs = [urine_sample],\n",
    "                outputs = [material_extract])\n",
    "            \n",
    "            \n",
    "            ## Labeling\n",
    "            material_label = Material(\n",
    "                name =\"labeled_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                type_ =\"Labeled Extract Name\")\n",
    "\n",
    "            \n",
    "            labelling_process = Process(\n",
    "                executes_protocol=labelling_metabolites,\n",
    "                inputs = [extraction_process.outputs[0]],\n",
    "                outputs = [material_label])\n",
    "            \n",
    "            \n",
    "            ## Chromatography\n",
    "#             separated_molecules = Material(\n",
    "#                 name = \"new_separated_molecules_{0}\".format(row[\"XOmicsmetaboID\"],\n",
    "#                 type_ =\"Labeled Extract Name\")  \n",
    "#             )\n",
    "            \n",
    "            instrument = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Chromatography Instrument\")), value = \"Agilent 1290\")\n",
    "            column_model = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Column model\")), value = \"Acquity UPLC CSH C18 column (Waters)\")\n",
    "            column_type = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Column type\")), value = \"reverse phase\")\n",
    "\n",
    "            \n",
    "            chromatography_process = Process(\n",
    "                name = \"chromatography_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol = chromatography,\n",
    "                parameter_values = [instrument, column_model, column_type],\n",
    "                inputs = [labelling_process.outputs[0]], \n",
    "                outputs = []\n",
    "                #outputs = [separated_molecules]\n",
    "            )\n",
    "            \n",
    "            ## Mass spectrometry\n",
    "            scan_polarity = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Scan polarity\")), value = \"switching positive and negative ion mode !! MAYBE SERPARATE INTO NEGATIVE AND POSITIVE ASSAY?\")\n",
    "            scan_range = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Scan m/z range\")), value = \"5-3000?\")\n",
    "            instrument = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Instrument\")), value = \"Agilent 6460\")\n",
    "            ion_source = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Ion source\")), value = \"ESI\")\n",
    "            mass_analyzer = ParameterValue(category = ProtocolParameter(parameter_name=OntologyAnnotation(term=\"Mass Analyzer\")), value = \"triple quadrupole\")\n",
    "            \n",
    "            \n",
    "            mass_spectrometry_process = Process(\n",
    "                name = \"mass_spectrometry_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol= mass_spectrometry,\n",
    "                parameter_values = [scan_polarity, scan_range, instrument, ion_source, mass_analyzer],\n",
    "               # inputs = [separated_molecules],\n",
    "                inputs = [],\n",
    "                outputs = [raw_datafile]\n",
    "            )\n",
    "            \n",
    "            \n",
    "           ## Data transformation\n",
    "            data_transformation_process = Process(\n",
    "                name = \"data_transformation_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol = data_transformation,\n",
    "                inputs = [raw_datafile],\n",
    "                outputs  = [normalized_datafile, derived_spectral_data_file]\n",
    "            )\n",
    "            \n",
    "            ## Metabolite identification\n",
    "            metabolite_identification_process = Process(\n",
    "                name = \"metabolite_identification_{0}\".format(row[\"XOmicsmetaboID\"]),\n",
    "                executes_protocol =  metabolite_identification,\n",
    "                inputs = [normalized_datafile],\n",
    "                outputs= [Data_Transformation_Name, MAF]\n",
    "            )\n",
    "            \n",
    "            ## Link processes\n",
    "            plink(extraction_process, labelling_process)\n",
    "            plink(labelling_process, chromatography_process)\n",
    "            plink(chromatography_process, mass_spectrometry_process)\n",
    "            plink(mass_spectrometry_process, data_transformation_process)\n",
    "            plink(data_transformation_process, metabolite_identification_process)\n",
    "            \n",
    "            ## Add samples, materials and data files to the steroids assay\n",
    "            Assay.other_material.append(material_extract)\n",
    "            Assay.other_material.append(material_label)\n",
    "            # Assay.other_material.append(separated_molecules)\n",
    "            Assay.data_files.append(raw_datafile)\n",
    "            Assay.data_files.append(normalized_datafile)\n",
    "            Assay.data_files.append(derived_spectral_data_file)\n",
    "            Assay.data_files.append(Data_Transformation_Name)                                                                                                   \n",
    "            Assay.data_files.append(MAF)\n",
    "            \n",
    "            ## Add processes to the steroids assay\n",
    "            Assay.process_sequence.append(extraction_process)\n",
    "            Assay.process_sequence.append(labelling_process)\n",
    "            Assay.process_sequence.append(chromatography_process)\n",
    "            Assay.process_sequence.append(mass_spectrometry_process)\n",
    "            Assay.process_sequence.append(data_transformation_process)\n",
    "            Assay.process_sequence.append(metabolite_identification_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "given-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add assays to study\n",
    "investigation.studies[0].assays.append(assay_genotype)\n",
    "investigation.studies[0].assays.append(assay_methylation)\n",
    "investigation.studies[0].assays.append(assay_metabolomics_amines)\n",
    "investigation.studies[0].assays.append(assay_metabolomics_OA)\n",
    "investigation.studies[0].assays.append(assay_metabolomics_steroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-webcam",
   "metadata": {},
   "source": [
    "# Write ISA-Tab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "regular-palmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 22:51:43,707 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [2995, 3000, 3005, 3010, 3015, 3020, 3025, 3030, 3035, 3040]\n",
      "2021-12-01 22:51:43,709 [WARNING]: isatab.py(write_study_table_files:1194) >> [2997, 2996, 2995, 2999, 2998, 3002, 3001, 3000, 3004, 3003, 3007, 3006, 3005, 3009, 3008, 3012, 3011, 3010, 3014, 3013, 3017, 3016, 3015, 3019, 3018, 3022, 3021, 3020, 3024, 3023, 3027, 3026, 3025, 3029, 3028, 3032, 3031, 3030, 3034, 3033, 3037, 3036, 3035, 3039, 3038, 3042, 3041, 3040, 3044, 3043]\n",
      "2021-12-01 22:51:43,709 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2995, 2997, 2996], [2995, 2999, 2998], [3000, 3002, 3001], [3000, 3004, 3003], [3005, 3009, 3008], [3005, 3007, 3006], [3010, 3012, 3011], [3010, 3014, 3013], [3015, 3017, 3016], [3015, 3019, 3018], [3020, 3022, 3021], [3020, 3024, 3023], [3025, 3027, 3026], [3025, 3029, 3028], [3030, 3034, 3033], [3030, 3032, 3031], [3035, 3037, 3036], [3035, 3039, 3038], [3040, 3042, 3041], [3040, 3044, 3043]]\n",
      "2021-12-01 22:51:43,753 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [2998, 3003, 3008, 3013, 3018, 3023, 3028, 3033, 3038, 3043]\n",
      "2021-12-01 22:51:43,755 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2998, 3046, 3045, 3047], [3003, 3049, 3048, 3050], [3008, 3052, 3051, 3053], [3013, 3055, 3054, 3056], [3018, 3058, 3057, 3059], [3023, 3061, 3060, 3062], [3028, 3064, 3063, 3065], [3033, 3067, 3066, 3068], [3038, 3070, 3069, 3071], [3043, 3073, 3072, 3074]]\n",
      "2021-12-01 22:51:43,757 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2998, 3046, 3045, 3047], [3003, 3049, 3048, 3050], [3008, 3052, 3051, 3053], [3013, 3055, 3054, 3056], [3018, 3058, 3057, 3059], [3023, 3061, 3060, 3062], [3028, 3064, 3063, 3065], [3033, 3067, 3066, 3068], [3038, 3070, 3069, 3071], [3043, 3073, 3072, 3074]]\n",
      "2021-12-01 22:51:43,778 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [2998, 3003, 3008, 3013, 3018, 3023, 3028, 3033, 3038, 3043]\n",
      "2021-12-01 22:51:43,781 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2998, 3076, 3075, 3077], [3003, 3079, 3078, 3080], [3008, 3082, 3081, 3083], [3013, 3085, 3084, 3086], [3018, 3088, 3087, 3089], [3023, 3091, 3090, 3092], [3028, 3094, 3093, 3095], [3033, 3097, 3096, 3098], [3038, 3100, 3099, 3101], [3043, 3103, 3102, 3104]]\n",
      "2021-12-01 22:51:43,782 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2998, 3076, 3075, 3077], [3003, 3079, 3078, 3080], [3008, 3082, 3081, 3083], [3013, 3085, 3084, 3086], [3018, 3088, 3087, 3089], [3023, 3091, 3090, 3092], [3028, 3094, 3093, 3095], [3033, 3097, 3096, 3098], [3038, 3100, 3099, 3101], [3043, 3103, 3102, 3104]]\n",
      "2021-12-01 22:51:43,848 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [2996, 3001, 3006, 3011, 3016, 3021, 3026, 3031, 3036, 3041]\n",
      "2021-12-01 22:51:43,849 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2996, 3111, 3110, 3113, 3112, 3114, 3115, 3116, 3117], [3001, 3119, 3118, 3121, 3120, 3122, 3123, 3124, 3125], [3006, 3127, 3126, 3129, 3128, 3130, 3131, 3132, 3133], [3011, 3135, 3134, 3137, 3136, 3138, 3139, 3140, 3141], [3016, 3143, 3142, 3145, 3144, 3146, 3147, 3148, 3149], [3021, 3151, 3150, 3153, 3152, 3154, 3155, 3156, 3157], [3026, 3159, 3158, 3161, 3160, 3162, 3163, 3164, 3165], [3031, 3167, 3166, 3169, 3168, 3170, 3171, 3172, 3173], [3036, 3175, 3174, 3177, 3176, 3178, 3179, 3180, 3181], [3041, 3183, 3182, 3185, 3184, 3186, 3187, 3188, 3189]]\n",
      "2021-12-01 22:51:43,851 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2996, 3111, 3110, 3113, 3112, 3114, 3115, 3116, 3117], [3001, 3119, 3118, 3121, 3120, 3122, 3123, 3124, 3125], [3006, 3127, 3126, 3129, 3128, 3130, 3131, 3132, 3133], [3011, 3135, 3134, 3137, 3136, 3138, 3139, 3140, 3141], [3016, 3143, 3142, 3145, 3144, 3146, 3147, 3148, 3149], [3021, 3151, 3150, 3153, 3152, 3154, 3155, 3156, 3157], [3026, 3159, 3158, 3161, 3160, 3162, 3163, 3164, 3165], [3031, 3167, 3166, 3169, 3168, 3170, 3171, 3172, 3173], [3036, 3175, 3174, 3177, 3176, 3178, 3179, 3180, 3181], [3041, 3183, 3182, 3185, 3184, 3186, 3187, 3188, 3189]]\n",
      "2021-12-01 22:51:43,937 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [2996, 3001, 3006, 3011, 3016, 3021, 3026, 3031, 3036, 3041]\n",
      "2021-12-01 22:51:43,939 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2996, 3196, 3195, 3198, 3197, 3199, 3200, 3201, 3202], [3001, 3204, 3203, 3206, 3205, 3207, 3208, 3209, 3210], [3006, 3212, 3211, 3214, 3213, 3215, 3216, 3217, 3218], [3011, 3220, 3219, 3222, 3221, 3223, 3224, 3225, 3226], [3016, 3228, 3227, 3230, 3229, 3231, 3232, 3233, 3234], [3021, 3236, 3235, 3238, 3237, 3239, 3240, 3241, 3242], [3026, 3244, 3243, 3246, 3245, 3247, 3248, 3249, 3250], [3031, 3252, 3251, 3254, 3253, 3255, 3256, 3257, 3258], [3036, 3260, 3259, 3262, 3261, 3263, 3264, 3265, 3266], [3041, 3268, 3267, 3270, 3269, 3271, 3272, 3273, 3274]]\n",
      "2021-12-01 22:51:43,941 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2996, 3196, 3195, 3198, 3197, 3199, 3200, 3201, 3202], [3001, 3204, 3203, 3206, 3205, 3207, 3208, 3209, 3210], [3006, 3212, 3211, 3214, 3213, 3215, 3216, 3217, 3218], [3011, 3220, 3219, 3222, 3221, 3223, 3224, 3225, 3226], [3016, 3228, 3227, 3230, 3229, 3231, 3232, 3233, 3234], [3021, 3236, 3235, 3238, 3237, 3239, 3240, 3241, 3242], [3026, 3244, 3243, 3246, 3245, 3247, 3248, 3249, 3250], [3031, 3252, 3251, 3254, 3253, 3255, 3256, 3257, 3258], [3036, 3260, 3259, 3262, 3261, 3263, 3264, 3265, 3266], [3041, 3268, 3267, 3270, 3269, 3271, 3272, 3273, 3274]]\n",
      "2021-12-01 22:51:44,024 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [2996, 3001, 3006, 3011, 3016, 3021, 3026, 3031, 3036, 3041]\n",
      "2021-12-01 22:51:44,025 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2996, 3281, 3280, 3283, 3282, 3284, 3285, 3286, 3287], [3001, 3289, 3288, 3291, 3290, 3292, 3293, 3294, 3295], [3006, 3297, 3296, 3299, 3298, 3300, 3301, 3302, 3303], [3011, 3305, 3304, 3307, 3306, 3308, 3309, 3310, 3311], [3016, 3313, 3312, 3315, 3314, 3316, 3317, 3318, 3319], [3021, 3321, 3320, 3323, 3322, 3324, 3325, 3326, 3327], [3026, 3329, 3328, 3331, 3330, 3332, 3333, 3334, 3335], [3031, 3337, 3336, 3339, 3338, 3340, 3341, 3342, 3343], [3036, 3345, 3344, 3347, 3346, 3348, 3349, 3350, 3351], [3041, 3353, 3352, 3355, 3354, 3356, 3357, 3358, 3359]]\n",
      "2021-12-01 22:51:44,027 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[2996, 3281, 3280, 3283, 3282, 3284, 3285, 3286, 3287], [3001, 3289, 3288, 3291, 3290, 3292, 3293, 3294, 3295], [3006, 3297, 3296, 3299, 3298, 3300, 3301, 3302, 3303], [3011, 3305, 3304, 3307, 3306, 3308, 3309, 3310, 3311], [3016, 3313, 3312, 3315, 3314, 3316, 3317, 3318, 3319], [3021, 3321, 3320, 3323, 3322, 3324, 3325, 3326, 3327], [3026, 3329, 3328, 3331, 3330, 3332, 3333, 3334, 3335], [3031, 3337, 3336, 3339, 3338, 3340, 3341, 3342, 3343], [3036, 3345, 3344, 3347, 3346, 3348, 3349, 3350, 3351], [3041, 3353, 3352, 3355, 3354, 3356, 3357, 3358, 3359]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create ISA files directory \n",
    "out_dir = \"isa_template\"\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "# write to ISA-Tab\n",
    "from isatools import isatab\n",
    "isatab.dump(investigation, out_dir)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "welcome-kitty",
   "metadata": {},
   "outputs": []
    }
   ],
   "source": [
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "with open (os.path.join(out_dir, 'isa.json'), \"w\") as out_file:\n",
    "    json.dump(\n",
    "        investigation,\n",
    "        out_file,\n",
    "        cls = ISAJSONEncoder,\n",
    "        sort_keys = True,\n",
    "        indent = 4,\n",
    "        separators = (',', ': ')\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa-api-py39",
   "language": "python",
   "name": "isa-api-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
